{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloading the libraries and setting the parameters\n",
    "\n",
    "import GAN_171103\n",
    "import importlib\n",
    "importlib.reload(GAN_171103) # For reloading after making changes\n",
    "from GAN_171103 import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=['cars_dummies','mammographic_masses',\n",
    "       'nursery','mushroom',\n",
    "       'winequality-white']\n",
    "path='data/{}.csv'\n",
    "pos=2\n",
    "df=pd.read_csv(path.format(paths[pos]))\n",
    "print(df.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rand_dim = 32 # 32 # needs to be ~data_dim\n",
    "base_n_count = 128 # 128\n",
    "\n",
    "nb_steps = 500 + 1 # 50000 # Add one for logging of the last interval\n",
    "batch_size = 128 # 64\n",
    "\n",
    "k_d = 1  # number of critic network updates per adversarial training step\n",
    "k_g = 1  # number of generator network updates per adversarial training step\n",
    "critic_pre_train_steps = 100 # 100  # number of steps to pre-train the critic before starting adversarial training\n",
    "log_interval = 100 # 100  # interval (in steps) at which to log loss summaries and save plots of image samples to disc\n",
    "learning_rate = 5e-4 # 5e-5\n",
    "data_dir = 'cache/'+paths[pos]+'/'\n",
    "generator_model_path, discriminator_model_path, loss_pickle_path = None, None, None\n",
    "\n",
    "# show = False\n",
    "show = True \n",
    "\n",
    "train = df.copy().reset_index(drop=True) \n",
    "\n",
    "# train = pd.get_dummies(train, columns=['Class'], prefix='Class', drop_first=True)\n",
    "label_cols = [ df.columns[-1] ]\n",
    "data_cols = [ i for i in train.columns if i not in label_cols ]\n",
    "#train[ data_cols ] = train[ data_cols ]  # scale to random noise size, one less thing to learn\n",
    "train_no_label = train[ data_cols ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the vanilla GAN and CGAN architectures\n",
    "\n",
    "k_d = 1  # number of critic network updates per adversarial training step\n",
    "learning_rate = 5e-4 # 5e-5\n",
    "arguments = [rand_dim, nb_steps, batch_size, \n",
    "             k_d, k_g, critic_pre_train_steps, log_interval, learning_rate, base_n_count,\n",
    "            data_dir, generator_model_path, discriminator_model_path, loss_pickle_path, show ]\n",
    "\n",
    "adversarial_training_GAN(arguments, train_no_label, data_cols ) # GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some of the generated data\n",
    "# First create the networks locally and load the weights\n",
    "\n",
    "import GAN_171103\n",
    "import importlib\n",
    "importlib.reload(GAN_171103) # For reloading after making changes\n",
    "from GAN_171103 import *\n",
    "\n",
    "seed = 17\n",
    "\n",
    "train = df.copy().reset_index(drop=True) # fraud only with labels from classification\n",
    "\n",
    "# train = pd.get_dummies(train, columns=['Class'], prefix='Class', drop_first=True)\n",
    "label_cols = [ train.columns[-1]  ]\n",
    "data_cols = [ i for i in train.columns if i not in label_cols ]\n",
    "#train[ data_cols ] = train[ data_cols ] / 10 # scale to random noise size, one less thing to learn\n",
    "train_no_label = train[ data_cols ]\n",
    "\n",
    "data_dim = len(data_cols)\n",
    "label_dim = len(label_cols)\n",
    "with_class = False\n",
    "#if label_dim > 0: with_class = True\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define network models\n",
    "\n",
    "generator_model, discriminator_model, combined_model = define_models_GAN(rand_dim, data_dim, base_n_count)\n",
    "generator_model.load_weights('cache/'+paths[pos]+'/GAN_generator_model_weights_step_500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now generate some new data\n",
    "\n",
    "test_size = 492 # Equal to all of the fraud cases\n",
    "\n",
    "x = get_data_batch(train_no_label, test_size, seed=3)\n",
    "z = np.random.normal(size=(test_size, rand_dim))\n",
    "if with_class:\n",
    "    labels = x[:,-label_dim:]\n",
    "    g_z = generator_model.predict([z, labels])\n",
    "else:\n",
    "    g_z = generator_model.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# check data\n",
    "# =============================================================================\n",
    "df2=pd.DataFrame(np.rint(np.abs(g_z)),columns=df.columns[:-1])\n",
    "df2=df2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  rebuild the neural network\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "def critic_network(x, data_dim, base_n_count):\n",
    "    x = layers.Dense(base_n_count*4, activation='relu')(x)\n",
    "    # x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(base_n_count*2, activation='relu')(x) # 2\n",
    "    # x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(base_n_count*1, activation='relu')(x) # 1\n",
    "    # x = layers.Dense(base_n_count*4, activation='relu')(x) # extra\n",
    "    # x = layers.Dense(base_n_count*4, activation='relu')(x) # extra\n",
    "    # x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    return x\n",
    "\n",
    "def generator_network(x, data_dim, base_n_count): \n",
    "    x = layers.Dense(base_n_count, activation='relu')(x)\n",
    "    x = layers.Dense(base_n_count*2, activation='relu')(x)\n",
    "    x = layers.Dense(base_n_count*4, activation='relu')(x)\n",
    "    x = layers.Dense(data_dim)(x)    \n",
    "    return x\n",
    "\n",
    "def discriminator_network(x, data_dim, base_n_count):\n",
    "    x = layers.Dense(base_n_count*4, activation='relu')(x)\n",
    "    # x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(base_n_count*2, activation='relu')(x)\n",
    "    # x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(base_n_count, activation='relu')(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    # x = layers.Dense(1)(x)\n",
    "    return x\n",
    "\n",
    "def define_models_GAN(rand_dim, data_dim, base_n_count, type=None):\n",
    "    generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
    "    generated_image_tensor = generator_network(generator_input_tensor, data_dim, base_n_count)\n",
    "\n",
    "    generated_or_real_image_tensor = layers.Input(shape=(data_dim,))\n",
    "    \n",
    "    if type == 'Wasserstein':\n",
    "        discriminator_output = critic_network(generated_or_real_image_tensor, data_dim, base_n_count)\n",
    "    else:\n",
    "        discriminator_output = discriminator_network(generated_or_real_image_tensor, data_dim, base_n_count)\n",
    "\n",
    "    generator_model = models.Model(inputs=[generator_input_tensor], outputs=[generated_image_tensor], name='generator')\n",
    "    discriminator_model = models.Model(inputs=[generated_or_real_image_tensor],\n",
    "                                       outputs=[discriminator_output],\n",
    "                                       name='discriminator')\n",
    "\n",
    "    combined_output = discriminator_model(generator_model(generator_input_tensor))\n",
    "    combined_model = models.Model(inputs=[generator_input_tensor], outputs=[combined_output], name='combined')\n",
    "    \n",
    "    return generator_model, discriminator_model, combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#rand_dim = 32 \n",
    "#base_n_count = 128\n",
    "#data_dim = len(data_cols) \n",
    "#'nursery','mushroom'\n",
    "paths=['cars_dummies','mammographic_masses','nursery','mushroom','winequality-white']\n",
    "path='data/{}.csv'\n",
    "pos=3\n",
    "df=pd.read_csv(path.format(paths[pos]))\n",
    "\n",
    "n_samples=10\n",
    "Xdf=df.iloc[:,:-1]    \n",
    "path_model='cache/'+paths[pos]+'/GAN_generator_model_weights_step_500.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_gan(n_samples,Xdf,path_model,rand_dim=32):\n",
    "    generator_model, discriminator_model, combined_model= define_models_GAN(rand_dim,data_dim=len(Xdf.columns),base_n_count=128)\n",
    "    generator_model.load_weights(path_model)\n",
    "    z = np.random.normal(size=(n_samples, rand_dim))\n",
    "    g_z = generator_model.predict(z)\n",
    "    \n",
    "    newdf = pd.DataFrame()\n",
    "    for i, col in enumerate(Xdf.columns):\n",
    "\n",
    "        if Xdf[col].dtype == 'int32' or Xdf[col].dtype == 'int64':\n",
    "            newdf[col] = np.rint(np.abs(g_z[:,i])).astype(int)    \n",
    "        elif Xdf[col].dtype == 'float_':\n",
    "            newdf[col] = np.abs(g_z[:,i])\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "data=generate_data_gan(n_samples,Xdf,path_model,rand_dim=32)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
